# ğŸ§  SumarizaÃ§Ã£o Abstrativa de Textos em PortuguÃªs

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um sistema de **sumarizaÃ§Ã£o abstrativa** para textos em portuguÃªs brasileiro, utilizando modelos Transformer prÃ©-treinados da biblioteca **Hugging Face**. A sumarizaÃ§Ã£o abstrativa busca **gerar um novo texto**, com linguagem prÃ³pria e criativa, mantendo o sentido e as informaÃ§Ãµes centrais do conteÃºdo original.

## ğŸ¯ Objetivos

- Implementar sumarizaÃ§Ã£o abstrativa real em portuguÃªs
- Adaptar cÃ³digo base para uso multilÃ­ngue com foco no idioma portuguÃªs
- Utilizar modelos prÃ©-treinados com fine-tuning real para sumarizaÃ§Ã£o
- Processar textos de atÃ© 500 palavras
- Gerar sumÃ¡rios com cerca de 50% do tamanho original, mantendo coesÃ£o

## ğŸ”§ Tecnologias Utilizadas

### ğŸ§  Modelos de IA
- [`csebuetnlp/mT5_multilingual_XLSum`](https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum): modelo com fine-tuning real para sumarizaÃ§Ã£o de notÃ­cias em portuguÃªs e outros idiomas.
- Modelos alternativos testados (fallbacks):
  - `unicamp-dl/ptt5-base-portuguese-vocab`
  - `pierreguillou/t5-base-pt-br-summarization`
  - `google/mt5-base`
  - `facebook/mbart-large-50-many-to-many-mmt`

### ğŸ“š Bibliotecas Python

```python
torch>=1.9.0
transformers>=4.21.0
sentencepiece>=0.1.97
```

## ğŸ“– FundamentaÃ§Ã£o TeÃ³rica

### TÃ©cnicas de SumarizaÃ§Ã£o

- **Extrativa**: copia trechos literais do texto original
- **Abstrativa**: reescreve com novas palavras, gerando um texto mais fluido e natural

### Modelos Transformer

A arquitetura Transformer revolucionou o NLP com:
- AtenÃ§Ã£o multi-head
- Paralelismo eficiente
- Capacidade de lidar com contexto longo

### Modelo Utilizado: `mT5_XLSum`

- Modelo `mT5` com fine-tuning para sumarizaÃ§Ã£o em mais de 40 idiomas
- Treinado com dados do **BBC News XLSum**
- Capaz de produzir resumos **naturais, coesos e criativos**

## ğŸš€ Como Executar

### 1. Criar ambiente virtual

```bash
python -m venv venv
```

### 2. Ativar ambiente virtual 

Windows:

```bash
venv\Scripts\activate
```

Linux/macOS:

```bash
source venv/bin/activate
```

### 3. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Rodar o cÃ³digo

```bash
python app.py
```

## âš™ï¸ Funcionalidades

- Interface em linha de comando
- GeraÃ§Ã£o de sumÃ¡rio com controle de temperatura, top-k, top-p
- ComparaÃ§Ã£o de diferentes versÃµes do sumÃ¡rio
- AnÃ¡lise de qualidade do sumÃ¡rio:
  - Overlap lexical
  - Cobertura do texto original
  - Grau de abstraÃ§Ã£o
- ReduÃ§Ã£o percentual do texto original

## ğŸ“Š Exemplo de Resultado

### Texto Original (400 palavras)

> Texto sobre InteligÃªncia Artificial com foco em aplicaÃ§Ãµes e implicaÃ§Ãµes Ã©ticas...

### SumÃ¡rio Gerado (180 palavras)

> A IA transforma a sociedade ao permitir que mÃ¡quinas executem tarefas humanas, como reconhecimento e decisÃµes. Impulsionada por dados e algoritmos, ela jÃ¡ atua em saÃºde, finanÃ§as e entretenimento. Apesar dos avanÃ§os, levanta questÃµes Ã©ticas como viÃ©s e desemprego. O desafio Ã© equilibrar inovaÃ§Ã£o e responsabilidade.

## ğŸ“½ï¸ DemonstraÃ§Ã£o em VÃ­deo

ğŸ“¹ [YouTube](https://youtu.be/4fzwEhTFcNM)

## ğŸ“‚ Estrutura do Projeto

```
pln/
â”œâ”€â”€ summarization/
â”‚   â”œâ”€â”€ app.py              # CÃ³digo principal com execuÃ§Ã£o e anÃ¡lise
â”‚   â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o
â”‚   â””â”€â”€ requirements.txt    # DependÃªncias
```

## ğŸ”— ReferÃªncias

1. **CÃ³digo Base Original**: [fabriciogmc/natural_language_processing](https://github.com/fabriciogmc/natural_language_processing/blob/main/python/nlp_summarization/abstractive_summarization_bart_en.py)
2. **XLSum Dataset**: Hasan et al. (2021). XLSum: A Cross-Lingual Abstractive Summarization Dataset.
3. **PTT5**: Carmo, D. et al. (2020). Pretraining and validating the T5 model on Brazilian Portuguese data.
4. **Transformers Library**: [Hugging Face](https://huggingface.co/transformers/)