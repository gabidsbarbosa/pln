import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer, BartForConditionalGeneration, BartTokenizer
import warnings
import re
warnings.filterwarnings("ignore")

def contar_palavras(texto):
    return len(texto.split())

def carregar_modelo_ptbr():
    print("Carregando modelo para portugu√™s...")

    modelos_ptbr = [
        "unicamp-dl/ptt5-base-portuguese-vocab",
        "pierreguillou/t5-base-pt-br-summarization",
        "google/mt5-base",
        "facebook/mbart-large-50-many-to-many-mmt"
    ]

    for modelo_name in modelos_ptbr:
        try:
            print(f"Tentando carregar: {modelo_name}")

            if "t5" in modelo_name.lower() or "mt5" in modelo_name.lower():
                tokenizer = T5Tokenizer.from_pretrained(modelo_name)
                model = T5ForConditionalGeneration.from_pretrained(modelo_name)
            elif "bart" in modelo_name.lower() or "mbart" in modelo_name.lower():
                tokenizer = BartTokenizer.from_pretrained(modelo_name)
                model = BartForConditionalGeneration.from_pretrained(modelo_name)

            print(f"‚úì Modelo {modelo_name} carregado com sucesso!")
            return tokenizer, model, modelo_name

        except Exception as e:
            print(f"‚ùå Erro com {modelo_name}: {e}")
            continue

    raise Exception("N√£o foi poss√≠vel carregar nenhum modelo")

def preprocessar_texto(texto):
    texto = re.sub(r'\n+', ' ', texto)
    texto = re.sub(r'\s+', ' ', texto)
    texto = re.sub(r'[^\w\s\.,;:!?()-]', '', texto)
    return texto.strip()

def pos_processar_sumario(sumario, texto_original):
    prefixos_remover = ["resuma:", "sum√°rio:", "resumo:", "sumarize:", "texto:"]
    for prefixo in prefixos_remover:
        if sumario.lower().startswith(prefixo):
            sumario = sumario[len(prefixo):].strip()

    if sumario:
        sumario = sumario[0].upper() + sumario[1:]

    if sumario and not sumario.endswith(('.', '!', '?')):
        sumario += '.'

    palavras_originais = set(texto_original.lower().split())
    palavras_sumario = sumario.lower().split()

    overlap = len(set(palavras_sumario) & palavras_originais) / len(set(palavras_sumario))
    if overlap > 0.8:
        print("‚ö†Ô∏è Sum√°rio muito similar ao original (poss√≠vel extra√ß√£o)")

    return sumario

def sumarizar_abstrativo(texto, tokenizer, model, modelo_name, max_length=180, min_length=40):
    texto_limpo = preprocessar_texto(texto)

    if "t5" in modelo_name.lower():
        texto_preparado = (
            "Leia o texto a seguir e produza um resumo criativo, reescrevendo com suas pr√≥prias palavras. "
            "Evite copiar frases diretamente. Concentre-se nas ideias principais e em como a IA afeta a sociedade. "
            f"Texto: {texto_limpo}"
        )
    elif "bart" in modelo_name.lower():
        texto_preparado = texto_limpo
    else:
        texto_preparado = f"Sum√°rio: {texto_limpo}"

    inputs = tokenizer.encode(
        texto_preparado,
        return_tensors="pt",
        max_length=512,
        truncation=True
    )

    with torch.no_grad():
        summary_ids = model.generate(
            inputs,
            max_length=max_length,
            min_length=min_length,
            temperature=0.8,
            top_k=50,
            top_p=0.9,
            do_sample=True,
            num_beams=6,
            length_penalty=1.0,
            repetition_penalty=1.2,
            no_repeat_ngram_size=3,
            early_stopping=False,
            eos_token_id=tokenizer.eos_token_id
        )

    sumario = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    sumario = pos_processar_sumario(sumario, texto_preparado)
    return sumario

def avaliar_qualidade_sumario(texto_original, sumario):
    palavras_original = set(texto_original.lower().split())
    palavras_sumario = set(sumario.lower().split())

    overlap_lexical = len(palavras_original & palavras_sumario) / len(palavras_sumario)
    cobertura = len(palavras_original & palavras_sumario) / len(palavras_original)
    nivel_abstracao = 1 - overlap_lexical

    print(f"\nüìä AN√ÅLISE DE QUALIDADE:")
    print(f"   Overlap lexical: {overlap_lexical:.2%}")
    print(f"   Cobertura do original: {cobertura:.2%}")
    print(f"   N√≠vel de abstra√ß√£o: {nivel_abstracao:.2%}")

    if nivel_abstracao > 0.4:
        print("   ‚úì Sum√°rio com boa abstra√ß√£o")
    elif nivel_abstracao > 0.2:
        print("   ‚ö†Ô∏è Sum√°rio moderadamente abstrativo")
    else:
        print("   ‚ùå Sum√°rio muito extrativo")

    return {
        'overlap': overlap_lexical,
        'cobertura': cobertura,
        'abstracao': nivel_abstracao
    }

def main():
    print("SUMARIZA√á√ÉO ABSTRATIVA AVAN√áADA - PORTUGU√äS")

    try:
        tokenizer, model, modelo_name = carregar_modelo_ptbr()
        print(f"‚úì Usando modelo: {modelo_name}")

        texto_original = """
        A Intelig√™ncia Artificial (IA) representa uma das maiores transforma√ß√µes tecnol√≥gicas do s√©culo XXI. Ela se refere √† capacidade de m√°quinas e sistemas computacionais de realizar tarefas que normalmente exigiriam intelig√™ncia humana, como reconhecimento de padr√µes, tomada de decis√µes, processamento de linguagem natural, aprendizado e adapta√ß√£o. Seu desenvolvimento tem sido impulsionado por avan√ßos em algoritmos, poder computacional e disponibilidade massiva de dados.

        Um dos ramos mais importantes da IA √© o machine learning (aprendizado de m√°quina), no qual os sistemas s√£o treinados a partir de grandes volumes de dados para identificar padr√µes e fazer previs√µes ou tomar decis√µes com base neles. O aprendizado profundo (deep learning), por sua vez, √© uma sub√°rea que utiliza redes neurais artificiais para resolver problemas complexos, como reconhecimento facial, tradu√ß√£o autom√°tica e diagn√≥sticos m√©dicos.

        A IA j√° est√° presente em diversas √°reas do nosso cotidiano. Nos smartphones, ela auxilia na digita√ß√£o preditiva, no reconhecimento de voz e na organiza√ß√£o de fotos. Em servi√ßos de streaming, algoritmos de IA recomendam m√∫sicas, filmes e s√©ries com base nos h√°bitos dos usu√°rios. No setor financeiro, a tecnologia √© usada para detectar fraudes e automatizar investimentos. Na sa√∫de, algoritmos ajudam no diagn√≥stico precoce de doen√ßas, como c√¢ncer e Alzheimer, aumentando as chances de tratamento eficaz.

        Apesar dos benef√≠cios, a IA tamb√©m levanta preocupa√ß√µes √©ticas e sociais. O uso de algoritmos pode refor√ßar preconceitos existentes, se forem treinados com dados enviesados. Al√©m disso, h√° o receio de substitui√ß√£o de empregos humanos por m√°quinas, o que exige uma requalifica√ß√£o da for√ßa de trabalho. A discuss√£o sobre a regula√ß√£o e uso respons√°vel da IA tem se intensificado, buscando garantir transpar√™ncia, privacidade e justi√ßa.

        Nos pr√≥ximos anos, espera-se que a IA se torne ainda mais integrada √† sociedade, com o avan√ßo de carros aut√¥nomos, assistentes virtuais mais inteligentes, rob√¥s colaborativos na ind√∫stria e sistemas educativos personalizados. O grande desafio ser√° equilibrar o desenvolvimento tecnol√≥gico com princ√≠pios √©ticos e humanos, promovendo uma IA a servi√ßo da melhoria da qualidade de vida.

        Em resumo, a Intelig√™ncia Artificial √© uma ferramenta poderosa que pode transformar positivamente o mundo, desde que seja desenvolvida e aplicada com responsabilidade, respeito √† diversidade e foco no bem-estar coletivo.
        """

        texto_original = " ".join(texto_original.split())
        palavras_original = contar_palavras(texto_original)

        print(f"\nüìÑ TEXTO ORIGINAL ({palavras_original} palavras):")
        print("-" * 50)
        print(texto_original[:300] + "..." if len(texto_original) > 300 else texto_original)

        print(f"\nü§ñ Gerando sum√°rio abstrativo...")
        sumario_principal = sumarizar_abstrativo(texto_original, tokenizer, model, modelo_name)
        palavras_sumario = contar_palavras(sumario_principal)

        print(f"\nüìã SUM√ÅRIO ABSTRATIVO ({palavras_sumario} palavras):")
        print("-" * 50)
        print(sumario_principal)

        avaliar_qualidade_sumario(texto_original, sumario_principal)

        percentual_reducao = (1 - palavras_sumario / palavras_original) * 100
        print(f"\nüìä ESTAT√çSTICAS:")
        print(f"   Palavras originais: {palavras_original}")
        print(f"   Palavras no sum√°rio: {palavras_sumario}")
        print(f"   Redu√ß√£o: {percentual_reducao:.1f}%")

    except Exception as e:
        print(f"\n‚ùå Erro: {e}")
        print("Verifique se instalou corretamente:")
        print("pip install torch transformers sentencepiece protobuf")

if __name__ == "__main__":
    main()
